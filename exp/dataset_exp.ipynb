{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import loguru\n",
    "import keras_cv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_images = \"../datasets/images/\"\n",
    "path_annot = \"../datasets/Annotations/\"\n",
    "\n",
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_annot, file_name)\n",
    "        for file_name in os.listdir(path_annot)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_images, file_name)\n",
    "        for file_name in os.listdir(path_images)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    \"jempol\",\n",
    "    \"five\",\n",
    "    \"three\",\n",
    "    \"v sign\"\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 5446.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = os.path.join(path_images, image_name)\n",
    "\n",
    "    boxes = []\n",
    "    classes = []\n",
    "    for obj in root.iter(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        classes.append(cls)\n",
    "\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = float(bbox.find(\"xmin\").text)\n",
    "        ymin = float(bbox.find(\"ymin\").text)\n",
    "        xmax = float(bbox.find(\"xmax\").text)\n",
    "        ymax = float(bbox.find(\"ymax\").text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "    class_ids = [\n",
    "        list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n",
    "        for cls in classes\n",
    "    ]\n",
    "    return image_path, boxes, class_ids\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "bbox = []\n",
    "classes = []\n",
    "for xml_file in tqdm(xml_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(xml_file)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = tf.ragged.constant(bbox)\n",
    "classes = tf.ragged.constant(classes)\n",
    "image_paths = tf.ragged.constant(image_paths)\n",
    "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_dataset(image_path, classes, bbox):\n",
    "    # Read Image\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": bbox,\n",
    "    }\n",
    "\n",
    "\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n",
    "\n",
    "resizing = keras_cv.layers.JitteredResize(\n",
    "    target_size=(640, 640),\n",
    "    scale_factor=(0.75, 1.3),\n",
    "    bounding_box_format=\"xyxy\",\n",
    ")\n",
    "\n",
    "def dict_to_tuple(inputs):\n",
    "        return inputs[\"images\"], bounding_box.to_dense(\n",
    "        inputs[\"bounding_boxes\"], max_boxes=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "data = data.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "data = data.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "data = data.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 640, 640, 3)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[180], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(images\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mprint\u001b[39m(labels\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(labels[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for images, labels in data.take(1):\n",
    "    print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv8Trainer:\n",
    "    def __init__(self, config_file):\n",
    "        self.config_file = config_file\n",
    "        self.config = self.arg_parse()\n",
    "\n",
    "    def arg_parse(self):\n",
    "        with open(self.config_file, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        config = StaticDotDict(config)\n",
    "        return config\n",
    "\n",
    "    def configure_model(self):\n",
    "        self.backbone = keras_cv.models.YOLOV8Backbone.from_preset(self.config.model.backbone)\n",
    "        yolo_v8_model = keras_cv.models.YOLOV8Detector(\n",
    "            backbone=self.backbone,\n",
    "            num_classes=len(self.config.model.classes),\n",
    "            bounding_box_format=self.config.model.bounding_box_format,\n",
    "            fpn_depth=self.config.model.fpn_depth,\n",
    "        )\n",
    "        self.model = yolo_v8_model\n",
    "        \n",
    "    def configure_optimizer(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def configure_callback(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def configure_trainer(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def visualize_dataset(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class StaticDotDict(dict):\n",
    "    \"\"\"\n",
    "    a dictionary that supports dot notation \n",
    "    as well as dictionary access notation \n",
    "    usage: d = DotDict() or d = DotDict({'val1':'first'})\n",
    "    set attributes: d.val2 = 'second' or d['val2'] = 'second'\n",
    "    get attributes: d.val2 or d['val2']\n",
    "    static mean that the dict is not dynamic, i.e. you can't add new attributes to it\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "    def __init__(self, dct):\n",
    "        for key, value in dct.items():\n",
    "            if hasattr(value, 'keys'):\n",
    "                value = StaticDotDict(value)\n",
    "            self[key] = value\n",
    "\n",
    "trainer = YOLOv8Trainer('../config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.configure_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 42s 686ms/step - loss: 950.1286 - box_loss: 3.0786 - class_loss: 947.0500\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 2s 646ms/step - loss: 864.2988 - box_loss: 3.1115 - class_loss: 861.1873\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 2s 615ms/step - loss: 654.6652 - box_loss: 2.9867 - class_loss: 651.6785\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 2s 681ms/step - loss: 727.9478 - box_loss: 2.6498 - class_loss: 725.2979\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 2s 679ms/step - loss: 807.0261 - box_loss: 3.1530 - class_loss: 803.8731\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 2s 600ms/step - loss: 918.0828 - box_loss: 3.4201 - class_loss: 914.6626\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 1s 651ms/step - loss: 774.6125 - box_loss: 1.8796 - class_loss: 772.7329\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 1s 621ms/step - loss: 603.2621 - box_loss: 2.1004 - class_loss: 601.1617\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 2s 651ms/step - loss: 468.0337 - box_loss: 2.6496 - class_loss: 465.3842\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 2951.7419 - box_loss: 1.1052 - class_loss: 2950.6367\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 1s 634ms/step - loss: 658.8619 - box_loss: 2.9059 - class_loss: 655.9559\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 2s 632ms/step - loss: 497.4371 - box_loss: 2.2418 - class_loss: 495.1952\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 2s 628ms/step - loss: 658.9752 - box_loss: 2.3185 - class_loss: 656.6566\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 2s 662ms/step - loss: 418.4583 - box_loss: 2.5808 - class_loss: 415.8775\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 2s 593ms/step - loss: 546.3516 - box_loss: 2.8161 - class_loss: 543.5355\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 2s 652ms/step - loss: 777.7331 - box_loss: 3.6134 - class_loss: 774.1197\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 2s 669ms/step - loss: 523.9874 - box_loss: 2.4186 - class_loss: 521.5688\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 1s 644ms/step - loss: 472.6268 - box_loss: 3.3328 - class_loss: 469.2940\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 2s 660ms/step - loss: 472.1284 - box_loss: 2.9869 - class_loss: 469.1415\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 2s 655ms/step - loss: 1141.8065 - box_loss: 3.4677 - class_loss: 1138.3389\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 2s 616ms/step - loss: 393.7837 - box_loss: 2.4772 - class_loss: 391.3065\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 1s 688ms/step - loss: 615.5594 - box_loss: 2.1153 - class_loss: 613.4441\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 359.8279 - box_loss: 2.1933 - class_loss: 357.6346\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 2s 602ms/step - loss: 790.7283 - box_loss: 2.8438 - class_loss: 787.8845\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 2s 687ms/step - loss: 287.4535 - box_loss: 1.9789 - class_loss: 285.4745\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 2s 671ms/step - loss: 430.9310 - box_loss: 2.4641 - class_loss: 428.4669\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 1s 637ms/step - loss: 312.0611 - box_loss: 1.9405 - class_loss: 310.1206\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 1s 628ms/step - loss: 734.7043 - box_loss: 2.0352 - class_loss: 732.6691\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 1s 649ms/step - loss: 316.5426 - box_loss: 2.1209 - class_loss: 314.4217\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 1s 605ms/step - loss: 551.4391 - box_loss: 2.2240 - class_loss: 549.2151\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 1s 633ms/step - loss: 543.6613 - box_loss: 2.1270 - class_loss: 541.5342\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 1s 589ms/step - loss: 663.0440 - box_loss: 2.2578 - class_loss: 660.7862\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 652.7698 - box_loss: 1.4746 - class_loss: 651.2952\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 226.3586 - box_loss: 1.8251 - class_loss: 224.5335\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 315.5774 - box_loss: 1.4652 - class_loss: 314.1121\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 270.9431 - box_loss: 1.7572 - class_loss: 269.1859\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 1s 646ms/step - loss: 383.5512 - box_loss: 2.3031 - class_loss: 381.2481\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 347.6062 - box_loss: 2.1209 - class_loss: 345.4853\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 1s 597ms/step - loss: 297.8877 - box_loss: 2.1535 - class_loss: 295.7342\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 1s 581ms/step - loss: 458.5049 - box_loss: 2.1483 - class_loss: 456.3566\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 2s 629ms/step - loss: 439.4861 - box_loss: 2.3014 - class_loss: 437.1847\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 386.4400 - box_loss: 1.9341 - class_loss: 384.5059\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 1s 605ms/step - loss: 304.2944 - box_loss: 2.0883 - class_loss: 302.2061\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 1s 587ms/step - loss: 242.0073 - box_loss: 1.8402 - class_loss: 240.1672\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 313.9665 - box_loss: 1.5469 - class_loss: 312.4196\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 1s 577ms/step - loss: 182.5541 - box_loss: 1.6642 - class_loss: 180.8900\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 1s 593ms/step - loss: 238.1542 - box_loss: 2.0259 - class_loss: 236.1283\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 430.1414 - box_loss: 1.6667 - class_loss: 428.4748\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 199.7442 - box_loss: 2.0917 - class_loss: 197.6526\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 1s 586ms/step - loss: 223.9039 - box_loss: 1.8554 - class_loss: 222.0484\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 1s 543ms/step - loss: 165.4829 - box_loss: 2.0213 - class_loss: 163.4617\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 188.6968 - box_loss: 1.8769 - class_loss: 186.8199\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 222.7840 - box_loss: 2.1466 - class_loss: 220.6374\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 295.9491 - box_loss: 2.3849 - class_loss: 293.5642\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 1s 567ms/step - loss: 158.3715 - box_loss: 1.7825 - class_loss: 156.5890\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 146.0799 - box_loss: 1.5807 - class_loss: 144.4993\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 433.5775 - box_loss: 3.3667 - class_loss: 430.2108\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 262.6928 - box_loss: 2.0474 - class_loss: 260.6454\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 293.3123 - box_loss: 2.7950 - class_loss: 290.5173\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 129.7717 - box_loss: 1.5551 - class_loss: 128.2166\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 374.1743 - box_loss: 1.9314 - class_loss: 372.2430\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 188.4494 - box_loss: 1.7960 - class_loss: 186.6534\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 1s 568ms/step - loss: 267.5316 - box_loss: 1.9921 - class_loss: 265.5395\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 1s 568ms/step - loss: 222.0858 - box_loss: 2.5878 - class_loss: 219.4980\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 1s 604ms/step - loss: 223.4487 - box_loss: 2.3125 - class_loss: 221.1362\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 153.0204 - box_loss: 1.7752 - class_loss: 151.2453\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 237.8378 - box_loss: 2.2311 - class_loss: 235.6067\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 1s 581ms/step - loss: 119.5862 - box_loss: 1.5898 - class_loss: 117.9964\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 229.9685 - box_loss: 1.7693 - class_loss: 228.1991\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 229.9419 - box_loss: 1.4380 - class_loss: 228.5040\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 1s 563ms/step - loss: 107.0916 - box_loss: 1.3881 - class_loss: 105.7035\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 1s 541ms/step - loss: 132.5965 - box_loss: 2.0407 - class_loss: 130.5558\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 115.5295 - box_loss: 1.6751 - class_loss: 113.8545\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 121.9063 - box_loss: 2.0780 - class_loss: 119.8283\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 1s 553ms/step - loss: 101.4346 - box_loss: 2.5454 - class_loss: 98.8892\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 204.1061 - box_loss: 1.6531 - class_loss: 202.4531\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 117.5442 - box_loss: 1.7114 - class_loss: 115.8328\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 1s 537ms/step - loss: 100.4436 - box_loss: 1.3916 - class_loss: 99.0520\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 1s 562ms/step - loss: 340.6327 - box_loss: 3.0627 - class_loss: 337.5700\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 1s 579ms/step - loss: 90.7764 - box_loss: 1.9553 - class_loss: 88.8211\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 93.6077 - box_loss: 1.5178 - class_loss: 92.0899\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 92.1440 - box_loss: 1.2876 - class_loss: 90.8564\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 126.7257 - box_loss: 1.9492 - class_loss: 124.7766\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 155.9588 - box_loss: 1.7011 - class_loss: 154.2577\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 1s 568ms/step - loss: 116.7079 - box_loss: 2.2083 - class_loss: 114.4996\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 659.1331 - box_loss: 0.8314 - class_loss: 658.3017\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 1s 614ms/step - loss: 75.6954 - box_loss: 1.9362 - class_loss: 73.7592\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 1s 557ms/step - loss: 87.6734 - box_loss: 1.2717 - class_loss: 86.4017\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 159.7807 - box_loss: 1.7563 - class_loss: 158.0244\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 1s 547ms/step - loss: 98.0442 - box_loss: 1.8368 - class_loss: 96.2074\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 83.7512 - box_loss: 1.9944 - class_loss: 81.7568\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 168.7799 - box_loss: 2.0393 - class_loss: 166.7406\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 102.2715 - box_loss: 2.4821 - class_loss: 99.7894\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 1s 533ms/step - loss: 113.1089 - box_loss: 1.5071 - class_loss: 111.6018\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 69.9827 - box_loss: 2.1615 - class_loss: 67.8213\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 252.1216 - box_loss: 2.3226 - class_loss: 249.7991\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 1s 559ms/step - loss: 155.0835 - box_loss: 1.7489 - class_loss: 153.3346\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 1s 562ms/step - loss: 80.9311 - box_loss: 2.1949 - class_loss: 78.7363\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 1s 554ms/step - loss: 73.6502 - box_loss: 1.7899 - class_loss: 71.8603\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 1s 556ms/step - loss: 72.7241 - box_loss: 1.9941 - class_loss: 70.7299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f252822f2e0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    box_loss='ciou',\n",
    "    classification_loss = 'binary_crossentropy'\n",
    "    \n",
    ")\n",
    "trainer.model.fit(data, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, y_true = next(iter(data.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 640, 640, 3), dtype=float32, numpy=\n",
       "array([[[[ 59.323235,  74.31762 ,  64.652824],\n",
       "         [ 57.9319  ,  74.19014 ,  63.9319  ],\n",
       "         [ 57.678032,  73.79466 ,  62.984734],\n",
       "         ...,\n",
       "         [201.67738 , 220.10696 , 217.91681 ],\n",
       "         [202.4734  , 219.04521 , 217.47432 ],\n",
       "         [203.10608 , 215.35953 , 216.31604 ]],\n",
       "\n",
       "        [[ 61.19662 ,  73.99538 ,  66.8024  ],\n",
       "         [ 60.73624 ,  74.26442 ,  65.6172  ],\n",
       "         [ 61.043056,  74.571236,  65.27312 ],\n",
       "         ...,\n",
       "         [201.04395 , 219.42569 , 218.6622  ],\n",
       "         [201.26924 , 219.04144 , 218.82394 ],\n",
       "         [202.63571 , 215.10535 , 216.62428 ]],\n",
       "\n",
       "        [[ 63.893253,  73.43256 ,  68.72473 ],\n",
       "         [ 64.67302 ,  74.89001 ,  67.63882 ],\n",
       "         [ 64.46439 ,  75.53133 ,  67.36935 ],\n",
       "         ...,\n",
       "         [200.7908  , 218.83124 , 220.00801 ],\n",
       "         [202.28159 , 218.3592  , 220.67606 ],\n",
       "         [202.92839 , 214.92009 , 218.33926 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[107.49262 , 109.34626 , 107.982796],\n",
       "         [105.68251 , 107.68251 , 104.88771 ],\n",
       "         [102.29032 , 106.37022 , 101.00504 ],\n",
       "         ...,\n",
       "         [212.      , 242.21832 , 244.76428 ],\n",
       "         [212.76465 , 242.6491  , 245.471   ],\n",
       "         [214.72792 , 240.61494 , 245.99509 ]],\n",
       "\n",
       "        [[105.612854, 107.612854, 105.55488 ],\n",
       "         [104.115974, 106.115974, 102.16639 ],\n",
       "         [100.493744, 104.57364 ,  98.45398 ],\n",
       "         ...,\n",
       "         [212.59708 , 242.59708 , 243.00565 ],\n",
       "         [213.56036 , 242.34348 , 244.57738 ],\n",
       "         [215.35358 , 241.1071  , 245.61981 ]],\n",
       "\n",
       "        [[103.113464, 105.38037 ,  99.81152 ],\n",
       "         [102.312256, 105.12207 ,  98.62451 ],\n",
       "         [101.662766, 104.86814 ,  96.861916],\n",
       "         ...,\n",
       "         [214.37    , 242.75037 , 243.56018 ],\n",
       "         [214.76506 , 242.85457 , 245.33911 ],\n",
       "         [216.36768 , 242.03088 , 247.85033 ]]],\n",
       "\n",
       "\n",
       "       [[[201.18605 , 202.59302 , 189.      ],\n",
       "         [201.34467 , 202.59302 , 189.53491 ],\n",
       "         [201.77908 , 202.59302 , 191.      ],\n",
       "         ...,\n",
       "         [187.51558 , 190.32953 , 188.14348 ],\n",
       "         [187.55815 , 190.3721  , 189.8373  ],\n",
       "         [187.10991 , 189.92386 , 188.22609 ]],\n",
       "\n",
       "        [[204.61629 , 204.04651 , 189.87616 ],\n",
       "         [204.7438  , 204.04651 , 190.82478 ],\n",
       "         [205.09303 , 204.04651 , 191.52325 ],\n",
       "         ...,\n",
       "         [190.      , 190.95349 , 188.47675 ],\n",
       "         [190.      , 190.95349 , 189.26396 ],\n",
       "         [189.63965 , 190.59314 , 188.34918 ]],\n",
       "\n",
       "        [[208.81396 , 206.20755 , 192.03491 ],\n",
       "         [208.69267 , 206.02827 , 193.36047 ],\n",
       "         [208.27083 , 206.27083 , 193.27083 ],\n",
       "         ...,\n",
       "         [189.09302 , 189.09302 , 188.      ],\n",
       "         [189.46744 , 189.46744 , 188.37442 ],\n",
       "         [189.88928 , 189.88928 , 188.79626 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[135.64665 , 135.94902 , 123.79784 ],\n",
       "         [135.31943 , 135.6218  , 124.00552 ],\n",
       "         [134.69763 , 135.      , 124.848816],\n",
       "         ...,\n",
       "         [112.04745 , 123.54669 , 115.57398 ],\n",
       "         [112.7008  , 125.85832 , 116.855156],\n",
       "         [111.45137 , 126.943954, 117.151184]],\n",
       "\n",
       "        [[133.55486 , 135.49994 , 122.5274  ],\n",
       "         [132.97823 , 134.81538 , 122.43172 ],\n",
       "         [132.91858 , 134.75574 , 123.83716 ],\n",
       "         ...,\n",
       "         [112.71243 , 127.97065 , 118.462006],\n",
       "         [112.33988 , 128.09561 , 118.17704 ],\n",
       "         [111.323654, 127.958336, 117.97821 ]],\n",
       "\n",
       "        [[132.32162 , 133.63174 , 120.992134],\n",
       "         [132.71234 , 132.71234 , 121.24726 ],\n",
       "         [131.98834 , 131.98834 , 121.98834 ],\n",
       "         ...,\n",
       "         [117.21167 , 130.      , 121.31506 ],\n",
       "         [116.17438 , 129.15512 , 120.16475 ],\n",
       "         [112.23833 , 127.47378 , 117.729576]]],\n",
       "\n",
       "\n",
       "       [[[207.67812 , 225.00597 , 213.34204 ],\n",
       "         [207.51079 , 224.48921 , 213.      ],\n",
       "         [207.61511 , 224.38489 , 213.      ],\n",
       "         ...,\n",
       "         [ 94.98874 ,  86.021576,  81.00516 ],\n",
       "         [ 93.43344 ,  86.021576,  80.22751 ],\n",
       "         [ 92.74188 ,  86.30127 ,  80.30127 ]],\n",
       "\n",
       "        [[207.69305 , 225.69305 , 213.51057 ],\n",
       "         [207.53348 , 225.53348 , 213.53348 ],\n",
       "         [207.68983 , 225.26335 , 213.53348 ],\n",
       "         ...,\n",
       "         [ 95.571976,  86.60481 ,  81.588394],\n",
       "         [ 94.224106,  86.81224 ,  81.01817 ],\n",
       "         [ 93.14296 ,  87.28639 ,  81.28639 ]],\n",
       "\n",
       "        [[208.65796 , 226.65796 , 213.97388 ],\n",
       "         [209.01929 , 226.98071 , 215.      ],\n",
       "         [209.03484 , 226.53868 , 215.      ],\n",
       "         ...,\n",
       "         [ 99.982124,  91.10352 ,  86.04356 ],\n",
       "         [ 99.135605,  91.8123  ,  86.00912 ],\n",
       "         [ 97.818634,  92.      ,  86.      ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[219.56165 , 236.26707 , 222.5351  ],\n",
       "         [219.56165 , 236.34013 , 222.34796 ],\n",
       "         [219.56165 , 236.61432 , 221.64566 ],\n",
       "         ...,\n",
       "         [113.01282 , 114.45117 , 108.231995],\n",
       "         [113.620026, 115.05838 , 108.8392  ],\n",
       "         [114.227234, 115.66559 , 108.30298 ]],\n",
       "\n",
       "        [[220.      , 236.70941 , 220.46448 ],\n",
       "         [220.      , 236.75073 , 220.38184 ],\n",
       "         [220.      , 236.90582 , 220.07166 ],\n",
       "         ...,\n",
       "         [113.5931  , 114.5931  , 109.15145 ],\n",
       "         [115.23915 , 116.23915 , 110.7975  ],\n",
       "         [116.56598 , 117.56598 , 111.30012 ]],\n",
       "\n",
       "        [[219.10725 , 236.779   , 218.10725 ],\n",
       "         [218.99237 , 236.66412 , 217.99237 ],\n",
       "         [218.99237 , 236.66412 , 217.99237 ],\n",
       "         ...,\n",
       "         [114.35756 , 114.69684 , 110.0272  ],\n",
       "         [115.38454 , 116.2462  , 111.31537 ],\n",
       "         [116.6079  , 117.6079  , 112.22821 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': <tf.Tensor: shape=(3, 32), dtype=float32, numpy=\n",
       " array([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1.],\n",
       "        [ 3., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1.],\n",
       "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1.]], dtype=float32)>,\n",
       " 'boxes': <tf.Tensor: shape=(3, 32, 4), dtype=float32, numpy=\n",
       " array([[[ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ]],\n",
       " \n",
       "        [[  0.   ,   0.   , 351.125, 640.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ]],\n",
       " \n",
       "        [[ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ],\n",
       "         [ -1.   ,  -1.   ,  -1.   ,  -1.   ]]], dtype=float32)>}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[[-2.79469299e+01,  2.99462891e+01,  4.76677979e+02,\n",
       "           4.86065674e+02],\n",
       "         [-1.24302856e+02,  6.43034973e+01,  4.77792725e+02,\n",
       "           4.82339447e+02],\n",
       "         [ 3.51041870e+01,  6.27543793e+01,  4.79013367e+02,\n",
       "           4.84588135e+02],\n",
       "         ...,\n",
       "         [ 1.19938034e+02,  5.68054016e+02,  1.19931931e+02,\n",
       "           1.19717712e+02],\n",
       "         [-4.81815033e+01,  1.11783005e+02,  2.39909088e+02,\n",
       "           2.40358841e+02],\n",
       "         [ 1.36240387e+02,  1.92228241e+02,  1.19372177e+02,\n",
       "           1.19735535e+02]],\n",
       " \n",
       "        [[ 1.31821304e+02,  9.56275330e+01,  4.76476562e+02,\n",
       "           4.84434784e+02],\n",
       "         [ 1.94170853e+02,  1.60662155e+02,  4.79326050e+02,\n",
       "           4.82406189e+02],\n",
       "         [ 3.22817017e+02,  1.29080200e+00,  4.77708008e+02,\n",
       "           4.82777649e+02],\n",
       "         ...,\n",
       "         [ 2.87891602e+02,  1.91776611e+02,  2.39892151e+02,\n",
       "           2.40411285e+02],\n",
       "         [ 3.83819519e+02,  3.51624390e+02,  2.40048645e+02,\n",
       "           2.40445923e+02],\n",
       "         [ 3.35797913e+02,  3.03761047e+02,  2.40118225e+02,\n",
       "           2.40397583e+02]],\n",
       " \n",
       "        [[ 1.29990891e+02,  3.19386292e+01,  4.81068420e+02,\n",
       "           4.82920624e+02],\n",
       "         [ 3.44020081e+01,  3.15490570e+01,  4.80329254e+02,\n",
       "           4.82841797e+02],\n",
       "         [ 1.29953903e+02, -6.44169159e+01,  4.81540344e+02,\n",
       "           4.83082825e+02],\n",
       "         ...,\n",
       "         [ 5.20115662e+02,  4.02307968e+01,  1.19757141e+02,\n",
       "           1.19990425e+02],\n",
       "         [ 5.52070374e+02,  4.87890350e+02,  1.19764587e+02,\n",
       "           1.20157257e+02],\n",
       "         [ 4.15844452e+02, -1.29669189e-01,  2.40034271e+02,\n",
       "           2.40250092e+02]]], dtype=float32),\n",
       " 'confidence': array([[0.53034973, 0.5286844 , 0.5270329 , 0.52488804, 0.5243276 ,\n",
       "         0.5238637 , 0.5238025 , 0.522016  , 0.5204136 , 0.52034044,\n",
       "         0.52001375, 0.5196419 , 0.5186115 , 0.51853895, 0.51715523,\n",
       "         0.51645595, 0.51639026, 0.51617163, 0.51607573, 0.51605046,\n",
       "         0.5160133 , 0.51551455, 0.5148516 , 0.5143524 , 0.51433486,\n",
       "         0.51424253, 0.51415086, 0.513945  , 0.51380223, 0.5136784 ,\n",
       "         0.513573  , 0.5135518 , 0.51294637, 0.51287955, 0.5128365 ,\n",
       "         0.5124124 , 0.51213354, 0.5121317 , 0.51209766, 0.5120802 ,\n",
       "         0.51189405, 0.51186043, 0.51176846, 0.511659  , 0.51154035,\n",
       "         0.51147765, 0.5114589 , 0.511414  , 0.5112225 , 0.51113284,\n",
       "         0.51093054, 0.51087666, 0.51065177, 0.5104875 , 0.5104553 ,\n",
       "         0.51029956, 0.51027775, 0.5100595 , 0.5099512 , 0.50988   ,\n",
       "         0.50980717, 0.50980365, 0.5096985 , 0.50968957, 0.50967985,\n",
       "         0.50967896, 0.5095066 , 0.50930375, 0.50929844, 0.5092551 ,\n",
       "         0.509205  , 0.50919414, 0.50918335, 0.5090895 , 0.50907826,\n",
       "         0.50906837, 0.5090448 , 0.50898063, 0.50894874, 0.5088636 ,\n",
       "         0.50885487, 0.5087096 , 0.5086442 , 0.508642  , 0.5086341 ,\n",
       "         0.5086125 , 0.50859207, 0.508578  , 0.5085709 , 0.50854594,\n",
       "         0.5085244 , 0.5084439 , 0.50843483, 0.50843436, 0.50842094,\n",
       "         0.508382  , 0.5083769 , 0.50835365, 0.50833285, 0.50826705],\n",
       "        [0.5340607 , 0.5326004 , 0.5289877 , 0.52815735, 0.52670276,\n",
       "         0.5262742 , 0.5253174 , 0.52500063, 0.5242007 , 0.52356493,\n",
       "         0.5234323 , 0.52288896, 0.5205042 , 0.519632  , 0.51908827,\n",
       "         0.5189821 , 0.51846576, 0.5184294 , 0.5184277 , 0.5176399 ,\n",
       "         0.5174713 , 0.5172545 , 0.5171032 , 0.51706403, 0.51666117,\n",
       "         0.5166118 , 0.51645297, 0.5164386 , 0.5156414 , 0.51562726,\n",
       "         0.5156036 , 0.51508194, 0.5150805 , 0.514584  , 0.5145333 ,\n",
       "         0.51435614, 0.5143402 , 0.51392937, 0.5135518 , 0.51354253,\n",
       "         0.5134045 , 0.5133154 , 0.5131191 , 0.5131027 , 0.512817  ,\n",
       "         0.5127378 , 0.5126628 , 0.51266277, 0.51237184, 0.51231605,\n",
       "         0.5122319 , 0.5121886 , 0.5121152 , 0.51163596, 0.51117724,\n",
       "         0.51109195, 0.51107264, 0.5109699 , 0.51092947, 0.5108428 ,\n",
       "         0.51069033, 0.5106365 , 0.5106332 , 0.5106172 , 0.51054627,\n",
       "         0.51054025, 0.51052284, 0.5105131 , 0.5105028 , 0.5104924 ,\n",
       "         0.510478  , 0.5104344 , 0.51040345, 0.5103137 , 0.5103012 ,\n",
       "         0.51027316, 0.51016134, 0.5100796 , 0.5100066 , 0.5099644 ,\n",
       "         0.5098728 , 0.5097006 , 0.50966424, 0.50961095, 0.5095796 ,\n",
       "         0.5095329 , 0.50951284, 0.5094795 , 0.50946766, 0.5094213 ,\n",
       "         0.50941586, 0.50940734, 0.50940204, 0.5093967 , 0.5093378 ,\n",
       "         0.5093164 , 0.50925446, 0.5092459 , 0.5092452 , 0.50922555],\n",
       "        [0.5248645 , 0.52385455, 0.52304363, 0.5227236 , 0.52270967,\n",
       "         0.522643  , 0.52185243, 0.52172077, 0.5212603 , 0.52099395,\n",
       "         0.5209014 , 0.52083766, 0.5197303 , 0.51966816, 0.5195696 ,\n",
       "         0.51931983, 0.5189573 , 0.5181666 , 0.5180988 , 0.51784617,\n",
       "         0.51764435, 0.51737857, 0.51671493, 0.51620364, 0.5161695 ,\n",
       "         0.5160804 , 0.51583284, 0.5157882 , 0.5157436 , 0.51556784,\n",
       "         0.5154997 , 0.5153411 , 0.5152067 , 0.515023  , 0.51466495,\n",
       "         0.5146542 , 0.51444423, 0.51416177, 0.51404256, 0.5136865 ,\n",
       "         0.51350516, 0.5134239 , 0.512673  , 0.51246136, 0.5124599 ,\n",
       "         0.51243466, 0.5121606 , 0.51182145, 0.5115804 , 0.5115721 ,\n",
       "         0.51125723, 0.51118165, 0.510865  , 0.5108645 , 0.5100885 ,\n",
       "         0.5099546 , 0.50988096, 0.50945324, 0.5093874 , 0.50935394,\n",
       "         0.50934887, 0.50921804, 0.50913507, 0.5090927 , 0.5089469 ,\n",
       "         0.5088985 , 0.50885075, 0.50884604, 0.50875944, 0.508681  ,\n",
       "         0.5085928 , 0.50843364, 0.5084107 , 0.5083937 , 0.50839305,\n",
       "         0.5083815 , 0.5083034 , 0.5082731 , 0.5082606 , 0.50823665,\n",
       "         0.50818825, 0.5081118 , 0.5080981 , 0.5080643 , 0.50797683,\n",
       "         0.5079695 , 0.50796473, 0.50795287, 0.5079477 , 0.5078994 ,\n",
       "         0.5078819 , 0.5078724 , 0.50781274, 0.507809  , 0.5078066 ,\n",
       "         0.5077444 , 0.5077417 , 0.507726  , 0.5077136 , 0.5077022 ]],\n",
       "       dtype=float32),\n",
       " 'classes': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1,\n",
       "         1, 1, 3, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 0, 2, 1, 3, 3,\n",
       "         1, 3, 1, 1, 3, 1, 1, 3, 1, 3, 2, 2, 1, 1, 1, 3, 3, 1, 3, 3, 1, 3,\n",
       "         3, 2, 3, 3, 3, 3, 1, 1, 1, 3, 1, 1, 1, 3, 2, 2, 1, 1, 2, 3, 3, 1,\n",
       "         3, 3, 2, 1, 3, 3, 1, 3, 2, 2, 1, 3],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1,\n",
       "         3, 1, 3, 1, 1, 1, 1, 1, 3, 3, 3, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 3,\n",
       "         3, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 3, 1, 1, 3, 3, 1, 1, 1, 3,\n",
       "         2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 3, 1, 1, 3, 3, 2, 1, 1, 1, 1, 2, 1, 2, 3, 3, 1, 3, 1,\n",
       "         2, 1, 1, 3, 1, 1, 3, 1, 1, 2, 1, 3, 1, 1, 3, 1, 1, 1, 3, 1, 2, 1,\n",
       "         1, 2, 1, 1, 1, 1, 1, 2, 0, 2, 3, 1]]),\n",
       " 'num_detections': array([100, 100, 100], dtype=int32)}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
